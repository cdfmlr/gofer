package gofer

import (
	"crypto/md5"
	"encoding/binary"
	"fmt"
	"io"
	"log"
	"net"
	"os"
	"path"
	"path/filepath"
	"strings"
	"sync"
	"time"
)

const DefaultBlockSize = 1 * 1024 * 1024 // 1 MiB

// å¤§æ–‡ä»¶ï¼ï¼
// æ€»è€Œè¨€ä¹‹å°±æ˜¯å¾ˆå¤§çš„æ–‡ä»¶, ä¸å®¹æ˜“ä¸€æ¬¡æ­£ç¡®ã€å¿«é€Ÿä¼ å®Œçš„é‚£ç§ã€‚
//
// é¢å¯¹è¿™ç§æ´ªæ°´çŒ›å…½ï¼Œè¿™é‡Œé‡‡å–çš„å¯¹ç­–æ˜¯ï¼š
//
//ã€Œå‘é€ç«¯ã€å…ˆæŠŠæ–‡ä»¶ä¿¡æ¯ç»™ã€Œæ¥æ”¶ç«¯ã€ï¼Œå…¶ä¸­åŒ…å«æ–‡ä»¶å¤§å°ï¼Œ
//ç„¶åç”±ã€Œæ¥æ”¶ç«¯ã€ä¸€æ®µä¸€æ®µåœ°è¯·æ±‚ä¸‹è½½ï¼Œæœ€ååˆæˆä¸€ä¸ªæ–‡ä»¶ã€‚
//
//è¿™æ ·ä¹Ÿå°±æ”¯æŒäº†æ–­ç‚¹ç»­ä¼ ã€å¹¶å‘å¤„ç†ã€‚
//
//å®šä¹‰å¦‚ä¸‹æ•°æ®ç»“æ„:
//
// - BigFileHeader
// - BigFileRequest
// - BigFileResponse
//
// - BigFileSender
// - BigFileReceiver
//
//å‘é€å¤§æ–‡ä»¶çš„æµç¨‹å°±å¯ä»¥è¡¨ç¤ºä¸º:
//
//  1. BigFileSender è¯»å–å¤§æ–‡ä»¶ä¿¡æ¯ï¼Œæ„å»º BigFileHeader
//  2. BigFileSender æŠŠ BigFileHeader å‘ç»™ BigFileReceiver
//  3. BigFileReceiver å‘é€ BigFileRequest ç»™ BigFileSenderï¼Œè¯·æ±‚ä¸‹è½½ä¸€æ®µæ–‡ä»¶
//  4. BigFileSender æŠŠè¯·æ±‚çš„æ–‡ä»¶æ®µå†™å…¥ BigFileResponse å‘ç»™ BigFileReceiver
//  5. BigFileReceiver æŠŠ BigFileResponse æ”¶åˆ°çš„æ–‡ä»¶éƒ¨åˆ†å†™å…¥ç£ç›˜
//  6. é‡å¤ 3~5, ç›´åˆ° BigFileReceiver æ¥æ”¶åˆ°å…¨éƒ¨æ–‡ä»¶éƒ¨åˆ†, ç„¶ååˆå¹¶ã€æ ¡éªŒæ–‡ä»¶ã€‚
//  7. BigFileReceiver å›ä¼  BigFileHeader ç»™ BigFileSenderï¼Œè¡¨ç¤ºæ¥æ”¶å®Œæˆã€‚
//  8. BigFileReceiver out, BigFileSender out. Done! ğŸ‰
//

// BigFileHeader æ˜¯å¤§æ–‡ä»¶ sender å‘ç»™ Receiver çš„æ–‡ä»¶ä¿¡æ¯è¯´æ˜ã€‚
// åŒ…å«ä¼ è¾“è¿‡ç¨‹éœ€è¦çš„ä¸€äº›å…³é”®å±æ€§ï¼š
//  - fileID  : æ–‡ä»¶IDï¼Œç”¨æ¥åœ¨åé¢çš„ä¼ è¾“è¿‡ç¨‹ä¸­è¡¨è¯†æ–‡ä»¶ï¼Œå…·ä½“çš„å®ç°æ˜¯æ–‡ä»¶çš„ md5 å’Œ
//  - fileName: æ–‡ä»¶å
//  - fileSize: æ–‡ä»¶å¤§å°, å•ä½æ˜¯ Byte
//  - fileHash: æ–‡ä»¶æ‘˜è¦ï¼Œç”¨æ¥åšæœ€ç»ˆæ ¡éªŒï¼Œå®ç°ä¸Šå…¶å®å°±æ˜¯ fileID
//
// BigFileHeader is Packet that:
//  - Type: 4
//  - Info: fileID(fileHash)
//  - Data: fileSize (const 8 Byte), fileName
type BigFileHeader struct {
	*Packet
	fileID   []byte // just a name, do not use this, call Getter/Setter instead
	fileName string // just a name, do not use this, call Getter/Setter instead
	fileSize uint64 // just a name, do not use this, call Getter/Setter instead
	fileHash []byte // just a name, do not use this, call Getter/Setter instead
}

const PacketTypeBigFileHeader = 4

func NewBigFileHeader(fileID []byte, fileName string, fileSize uint64) *BigFileHeader {
	h := &BigFileHeader{Packet: NewPacket(PacketTypeBigFileHeader, make([]byte, 0), make([]byte, 0))}

	h.SetFileID(fileID)
	h.SetFileName(fileName)
	h.SetFileSize(fileSize)

	//log.Printf("[Debug] NewBigFileHeader: %v %v %v", h.FileID(), h.FileName(), h.FileSize())

	return h
}

// PacketAsBigFileHeader convert packet to BigFileHeader
// Notice: only for packets whose Type==PacketTypeBigFileHeader
func PacketAsBigFileHeader(packet *Packet) *BigFileHeader {
	return &BigFileHeader{Packet: packet}
}

func (b *BigFileHeader) FileID() []byte {
	return b.Info
}

func (b *BigFileHeader) SetFileID(fileID []byte) {
	b.Info = fileID
	b.InfoSize = uint32(len(fileID))
}

func (b *BigFileHeader) FileName() string {
	return string(b.Data[8:]) // å‰ 8 Byte æ˜¯ uint64 çš„ fileSize
}

func (b *BigFileHeader) SetFileName(fileName string) {
	b.DataSize = uint32(8 + len(fileName))
	buf := make([]byte, b.DataSize)
	if len(b.Data) >= 8 {
		copy(buf, b.Data[:8])
	}
	copy(buf[8:], []byte(fileName))
	b.Data = buf
}

func (b *BigFileHeader) FileSize() uint64 {
	return binary.BigEndian.Uint64(b.Data[:8])
}

func (b *BigFileHeader) SetFileSize(fileSize uint64) {
	if b.DataSize < 8 {
		b.DataSize = 8
		b.Data = make([]byte, 8)
	}
	binary.BigEndian.PutUint64(b.Data[:8], fileSize)
}

func (b *BigFileHeader) FileHash() []byte {
	return b.FileID()
}

func (b *BigFileHeader) SetFileHash(fileHash []byte) {
	b.SetFileID(fileHash)
}

// BigFileRequest æ˜¯å¤§æ–‡ä»¶çš„ Receiver å‘ç»™ sender çš„æ–‡ä»¶æ®µè¯·æ±‚ã€‚
//
// Receiver é€šè¿‡å‘é€ BigFileRequest ç»™ sender æ¥è¯·æ±‚æŸä¸€æ®µæ–‡ä»¶ã€‚
// æ‰€ä»¥è¯´, BigFileRequest ä¸­åŒ…æ‹¬è¯·æ±‚æ–‡ä»¶çš„ fileID ä»¥åŠæ–‡ä»¶æ®µçš„èµ·å§‹
// ä½ç½® start (å­—èŠ‚æ•°) å’Œè¯·æ±‚ä¸‹è½½é•¿åº¦ length (å­—èŠ‚æ•°)ã€‚
//
// BigFileRequest is Packet that:
//  - Type: 5
//  - Info: fileID
//  - Data: start(const 8 Byte), length(const 8 Byte)
type BigFileRequest struct {
	*Packet
	fileID []byte // just a name, do not use this, call Getter/Setter instead
	start  uint64 // just a name, do not use this, call Getter/Setter instead
	length uint64 // just a name, do not use this, call Getter/Setter instead
}

const PacketTypeBigFileRequest = 5

func NewBigFileRequest(fileID []byte, start uint64, length uint64) *BigFileRequest {
	r := &BigFileRequest{Packet: NewPacket(PacketTypeBigFileRequest, make([]byte, 0), make([]byte, 0))}
	r.SetFileID(fileID)
	r.SetStart(start)
	r.SetLength(length)

	//log.Println("[Debug] NewBigFileRequest:", r.FileID(), r.Start(), r.Length())

	return r
}

// PacketAsBigFileRequest convert packet to BigFileRequest
// Notice: only for packets whose Type==PacketTypeBigFileRequest
func PacketAsBigFileRequest(packet *Packet) *BigFileRequest {
	return &BigFileRequest{Packet: packet}
}

func (b *BigFileRequest) FileID() []byte {
	return b.Info
}

func (b *BigFileRequest) SetFileID(fileID []byte) {
	b.Info = fileID
	b.InfoSize = uint32(len(b.Info))
}

func (b *BigFileRequest) Start() uint64 {
	return binary.BigEndian.Uint64(b.Data[:8])
}

func (b *BigFileRequest) SetStart(start uint64) {
	if len(b.Data) < 16 {
		b.Data = make([]byte, 16)
		b.DataSize = 16
	}
	binary.BigEndian.PutUint64(b.Data[:8], start)
}

func (b *BigFileRequest) Length() uint64 {
	return binary.BigEndian.Uint64(b.Data[8:])
}

func (b *BigFileRequest) SetLength(length uint64) {
	if len(b.Data) < 16 {
		b.Data = make([]byte, 16)
		b.DataSize = 16
	}
	binary.BigEndian.PutUint64(b.Data[8:], length)
}

// BigFileResponse æ˜¯å¤§æ–‡ä»¶çš„ sender å‘ç»™ Receiver çš„æ–‡ä»¶æ®µ
//
//  - fileID: æ–‡ä»¶ ID
//  - start: èµ·å§‹ä½ç½®
//  - fileContent: æ–‡ä»¶æ®µçš„å†…å®¹
//
// BigFileResponse is Packet that:
//  - Type: 6
//  - Info: start(const 8 Byte), fileID
//  - Data: fileContent
type BigFileResponse struct {
	*Packet
	fileID      []byte // just a name, do not use this, call Getter/Setter instead
	start       uint64 // just a name, do not use this, call Getter/Setter instead
	fileContent []byte // just a name, do not use this, call Getter/Setter instead
}

func NewBigFileResponse(fileID []byte, start uint64, fileContent []byte) *BigFileResponse {
	r := &BigFileResponse{Packet: NewPacket(PacketTypeBigFileResponse, make([]byte, 0), make([]byte, 0))}
	r.SetFileID(fileID)
	r.SetStart(start)
	r.SetFileContent(fileContent)
	return r
}

const PacketTypeBigFileResponse = 6

// PacketAsBigFileResponse convert packet to BigFileResponse
// Notice: only for packets whose Type==PacketTypeBigFileResponse
func PacketAsBigFileResponse(packet *Packet) *BigFileResponse {
	return &BigFileResponse{Packet: packet}
}

func (b *BigFileResponse) FileContent() []byte {
	return b.Data
}

func (b *BigFileResponse) SetFileContent(fileContent []byte) {
	b.Data = fileContent
	b.DataSize = uint32(len(b.Data))
}

func (b *BigFileResponse) Start() uint64 {
	return binary.BigEndian.Uint64(b.Info[:8])
}

func (b *BigFileResponse) SetStart(start uint64) {
	if b.InfoSize < 8 {
		b.InfoSize = 8
		b.Info = make([]byte, 8)
	}
	binary.BigEndian.PutUint64(b.Info[:8], start)
}

func (b *BigFileResponse) FileID() []byte {
	return b.Info[8:]
}

func (b *BigFileResponse) SetFileID(fileID []byte) {
	b.InfoSize = uint32(8 + len(fileID))
	buf := make([]byte, b.InfoSize)
	if len(b.Info) >= 8 {
		copy(buf, b.Info[:8])
	}
	copy(buf[8:], fileID)
	b.Info = buf
}

// FileIDString returns Sprintf("%x", fileID)
func FileIDString(fileID []byte) string {
	return fmt.Sprintf("%x", fileID)
}

// BigFileSender æ˜¯å‘å¤§æ–‡ä»¶ç”¨çš„ä¸œè¥¿
// å®ç° Sender æ¥å£
//
// å’Œ Messageã€SimpleFile é‚£ç§ä¸åŒ, BigFileSender å…¶å®æ˜¯ä¸€ä¸ª"æœåŠ¡"äº†ï¼Œ
// å®ƒç›‘å¬ conn, ä»é‡Œé¢è¯»è¯·æ±‚ï¼ˆBigFileRequestï¼‰ï¼Œå†™å“åº”ï¼ˆBigFileResponseï¼‰
type BigFileSender struct {
	filePathMap sync.Map // {fileIDString: "path/to/file"}
	headerMap   sync.Map // {fileIDString: BigFileHeader}
}

func NewBigFileSender() *BigFileSender {
	return &BigFileSender{}
}

func (s *BigFileSender) AppendFile(filePath string) {
	fileName := filepath.Base(filePath)
	// Open file
	file, err := os.Open(filePath)
	if err != nil {
		fmt.Println("Open file failed:", err)
		return
	}
	defer file.Close()

	// Get hash and size
	h := md5.New()
	fileSize, err := io.Copy(h, file)
	if err != nil {
		log.Fatal(err)
	}
	fileHash := h.Sum(nil)

	// Store
	fileIDString := FileIDString(fileHash)

	//log.Println("[Debug] AppendFile:", fileIDString, filePath, fileName, fileSize)

	s.filePathMap.Store(fileIDString, filePath)
	s.headerMap.Store(fileIDString, *NewBigFileHeader(fileHash, fileName, uint64(fileSize)))
}

// Send å‘ conn å‘é€ä¸€æ¬¡å¤´ï¼ˆsendHeaderï¼‰ï¼Œç„¶åè°ƒç”¨ sendResponse ç›‘å¬ conn,
// ä»é‡Œé¢è¯»è¯·æ±‚ï¼ˆBigFileRequestï¼‰ï¼Œå†™å“åº”ï¼ˆBigFileResponseï¼‰ï¼›
// å¦‚æœé•¿æ—¶é—´æ²¡æœ‰è¯·æ±‚åˆ™é‡æ–°ä½¿ç”¨ sendHeader å‘é€ Header
func (s BigFileSender) Send(conn net.Conn) {
	// TODO: é”™è¯¯æ—¶é€šçŸ¥è¯·æ±‚è€…
	s.sendHeader(conn)
	resp := s.sendResponse(conn)
	for {
		select {
		case ok := <-resp:
			if ok {
				return
			}
		case <-time.After(3 * time.Second):
			s.sendHeader(conn)
		}
	}
}

// sendResponse ç›‘å¬ conn, ä»é‡Œé¢è¯»è¯·æ±‚ï¼ˆBigFileRequestï¼‰ï¼Œå†™å“åº”ï¼ˆBigFileResponseï¼‰
func (s BigFileSender) sendResponse(conn net.Conn) chan bool {
	done := make(chan bool)

	go func() {
		for {
			// è·å–è¯·æ±‚
			packet, err := PacketFromReader(conn)
			//log.Println("[DEBUG] sendResponse, got from conn:", packet.Header)
			if err != nil {
				log.Fatal(err)
			}
			if packet.Type == PacketTypeBigFileHeader { // Receiver å›ä¼  headerï¼Œæ–‡ä»¶å‘é€ç»“æŸ
				header := PacketAsBigFileHeader(packet)
				fileIDString := FileIDString(header.FileID())

				log.Println("BigFileSender: over:", fileIDString)

				done <- true // è¿™æ‰æ˜¯çœŸçš„å‘å®Œäº†ï¼Œå›ä¼  trueï¼Œç»“æŸå·¥ä½œ
				return
			}
			if packet.Type != PacketTypeBigFileRequest {
				log.Println("BigFileSender: req.Type != PacketTypeBigFileRequest:", packet.Header)
				done <- false
				return
			}
			req := PacketAsBigFileRequest(packet)

			// è·å–å“åº”
			resp, err := s.responseReq(req)
			if err != nil {
				log.Println("BigFile response failed:", err)
				done <- false
				return
			}

			//log.Println("[debug] sendResponse:", FileIDString(resp.FileID()), resp.DataSize)

			// å‘é€å“åº”
			if n, err := resp.WriteTo(conn); err != nil {
				fmt.Println("BigFile send failed:", err)
			} else {
				fmt.Println("BigFile sent successfully: length =", n)
			}

			done <- false // è¿˜æœ‰ç»§ç»­å‘€ï¼Œæ‰€ä»¥æ˜¯ false
		}
	}()

	return done
}

// responseReq è§£æ BigFileRequest çš„è¯·æ±‚ï¼Œæ„é€  BigFileResponse
func (s BigFileSender) responseReq(req *BigFileRequest) (*BigFileResponse, error) {
	//log.Println("[Debug] responseReq", req.FileID(), req.Start())
	// Open file
	filePath, ok := s.filePathMap.Load(FileIDString(req.FileID()))
	if !ok {
		return nil, fmt.Errorf("bigFileSender: resource not found")
	}

	file, err := os.Open(filePath.(string))
	if err != nil {
		return nil, fmt.Errorf("bigFileSender: resource not found: %v", err)
	}
	defer file.Close()

	// Read
	buf := make([]byte, req.Length())
	n, err := file.ReadAt(buf, int64(req.Start()))
	if err != nil && err != io.EOF {
		return nil, fmt.Errorf("bigFileSender: read file error: %v", err)
	}

	// make a response
	resp := NewBigFileResponse(req.FileID(), req.Start(), buf[:n])

	log.Printf("[bigFileSender] response: flie=%s offset=%v length=%v",
		filePath, req.Start(), n)

	return resp, nil
}

// sendHeader å‘ conn å‘é€ä¸€æ¬¡ BigFileHeader
func (s BigFileSender) sendHeader(conn net.Conn) {
	s.headerMap.Range(func(key, value interface{}) bool {
		header := value.(BigFileHeader)
		//log.Printf("[Debug] BigFileSender.sendHeader: %v %v %v", header.FileID(), header.FileName(), header.FileSize())
		_, _ = header.WriteTo(conn)
		return true
	})
}

// BigFileSender æ˜¯æ”¶å¤§æ–‡ä»¶ç”¨çš„ä¸œè¥¿:
// å®ç°äº† PacketReceiver æ¥å£
//
// æ¥æ”¶å¤§æ–‡ä»¶è¿™é‡Œè®¾è®¡æˆç”¨ Master-Worker æ¨¡å¼ï¼š
// BigFileReceiver æ˜¯ Master, åªæ˜¯æŒ‡æ´¾ã€ç®¡ç†å·¥ä½œ;
// è€Œå…·ä½“çš„æ–‡ä»¶ä¸‹è½½å·¥ä½œç”± BigFileReceiverWorker æ¥åšã€‚
type BigFileReceiver struct {
	workerMap sync.Map // {FileIDString(fileID): BigFileReceiverWorker}
	wg        sync.WaitGroup
}

func NewBigFileReceiver() *BigFileReceiver {
	//log.Println("[DEBUG] NewBigFileReceiver")
	return &BigFileReceiver{}
}

// Receive å¤„ç†æ¥æ”¶åˆ°çš„ BigFileHeader å’Œ BigFileResponse
// åˆ†å‘ç»™ handleBigFileHeader å’Œ handleBigFileResponse æ–¹æ³•å¤„ç†
func (r *BigFileReceiver) Receive(packet *Packet, conn net.Conn) chan bool {
	done := make(chan bool, 1)

	//log.Printf("[Debug] BigFileReceiver(%p).Receive: %v", r, packet)
	switch packet.Type {
	case PacketTypeBigFileHeader:
		r.handleBigFileHeader(PacketAsBigFileHeader(packet), conn)
	case PacketTypeBigFileResponse:
		r.handleBigFileResponse(PacketAsBigFileResponse(packet), conn)
	default:
		log.Printf("BigFileReceiver got an unknown Packet: %#v", packet)
	}

	go func() {
		r.wg.Wait()
		done <- true
	}()

	return done // æœ‰ worker å°±è¿˜è¦ç»§ç»­
}

// handleBigFileHeader å¤„ç†æ”¶åˆ°çš„å¤§æ–‡ä»¶å¤´:
// æ–°å»ºä¸€ä¸ª worker å»å¤„ç†ï¼Œç»“æŸååˆ é™¤ workerã€‚
func (r *BigFileReceiver) handleBigFileHeader(header *BigFileHeader, conn net.Conn) {
	fileID := FileIDString(header.FileID())

	//log.Println("[DEBUG] BigFileReceiver handleBigFileHeader:", fileID)

	_, ok := r.workerMap.Load(fileID)
	if ok { // file is already exist
		//log.Println("handleBigFileHeader: file is already on receiving")
		return
	}

	worker := NewBigFileReceiverWorker(header)
	r.wg.Add(1)
	r.workerMap.Store(fileID, worker)
	//_h, _ok := r.workerMap.Load(fileID)
	//log.Println("[DEBUG] handleBigFileHeader:", r.workerMap, r)
	//log.Printf("[DEBUG] handleBigFileHeader: %p %p", &r.workerMap, r)
	workerDone := worker.Run(conn)

	go func() { // cleanup
		select {
		case f := <-workerDone:
			//log.Println("[DEBUG] workerDone:", f)
			r.workerMap.Delete(f)
			r.wg.Done()
		}
	}()
}

// handleBigFileResponse å¤„ç†æ”¶åˆ°çš„ BigFileResponseï¼š
// æ‰¾åˆ°å¯¹åº”çš„ worker å»å¤„ç†
func (r *BigFileReceiver) handleBigFileResponse(response *BigFileResponse, conn net.Conn) {
	fileIDString := FileIDString(response.FileID())
	//log.Println("[DEBUG] BigFileReceiver handleBigFileResponse:", fileIDString)
	//log.Printf("[DEBUG] BigFileReceiver handleBigFileResponse: %p %p", &r.workerMap, r)
	worker, ok := r.workerMap.Load(fileIDString)
	if !ok { // worker is not exist
		log.Println("BigFileReceiver: worker not found: fileID =", fileIDString)
		return
	}
	worker.(*BigFileReceiverWorker).Receive(response)
}

// BigFileReceiverWorker è´Ÿè´£æ¥æ”¶ä¸€ä¸ªå¤§æ–‡ä»¶ã€‚
//
// ä¸€ä¸ª Worker åªä¸“æ³¨å¤„ç†ä¸€ä¸ªå¤§æ–‡ä»¶ã€‚
// BigFileReceiver é€šè¿‡æŠŠ BigFileHeader æŒ‡æ´¾ç»™ Workerï¼Œè®© Worker è‡ªè¡Œå¤„ç†ä¸€ä¸ªå¤§æ–‡ä»¶çš„ä¸‹è½½å·¥ä½œã€‚
//
// Worker ä¼šåœ¨ $PWD æ–°å»ºä¸€ä¸ªä»¥ ".{fileID}" ä¸ºåçš„ç›®å½•ï¼ˆç§°ä¸º saveDirï¼‰ï¼Œ
// æ¯æ¬¡è¯·æ±‚ä¸‹è½½ blockSize å¤§å°çš„æ–‡ä»¶ç‰‡æ®µ, ä¿å­˜åˆ° saveDir, æ–‡ä»¶åä¸º "{blockIndex}.block",
// æŠŠ savedBlock ä¸­å¯¹åº”çš„å—ä½ç½®æ ‡è®°ä¸º 1ã€‚
//
// é‡å¤ä¸‹è½½è¿‡ç¨‹ï¼Œç›´åˆ° savedBlock å…¨ä¸º 1ï¼Œç„¶ååˆå¹¶æ–‡ä»¶ï¼Œè®¡ç®— md5 å’Œï¼Œæ£€æŸ¥æ˜¯å¦æ­£ç¡®ã€‚
// æ­£ç¡®åˆ™ mv mergedFile $PWD/{fileName}, ä¸æ­£ç¡®å°±ä¸¢å¼ƒã€‚
//
// æ–­ç‚¹ç»­ä¼ : Worker å¹¶ä¸æ˜¯ç›´æ¥æ–°å»º saveDirã€‚å¦‚æœ saveDir å­˜åœ¨ï¼Œåˆ™æ‰“å¼€ï¼Œ
// ä»é‡Œé¢è¯»å–å·²ä¿å­˜çš„æ–‡ä»¶ç‰‡æ®µï¼Œæ›´æ–° savedBlockï¼Œç„¶åå†å¼€å§‹ä¸‹è½½ç¼ºå¤±éƒ¨åˆ†ã€‚
type BigFileReceiverWorker struct {
	header     *BigFileHeader // å¤§æ–‡ä»¶å¤´
	saveDir    string         // ä¸´æ—¶ç›®å½•çš„ä¿å­˜è·¯å¾„
	blockSize  uint64         // å—å¤§å°, XXX: ç¬¬ä¸€ä¸ªç‰ˆæœ¬ä¸ºäº†æ–¹ä¾¿ï¼Œå›ºå®š blockSize ä¸º DefaultBlockSize
	numBlock   uint64         // å—æ•°é‡
	savedBlock []bool         // bitmap: å·²ä¿å­˜å—ä¸º 1ï¼Œæœªä¿å­˜çš„ä¸º 0
	done       chan string    // worker å·¥ä½œç»“æŸåé€šçŸ¥ master (BigFileReceiver), æˆ– master æ¥ç»ˆæ­¢ worker
	wait       chan int       // è¯·æ±‚ä¸‹è½½ä¹‹åç­‰å¾…æ¥æ”¶, å€¼æ˜¯ blockIndex
	allSaved   chan bool      // æ‰€æœ‰éƒ¨åˆ†éƒ½ä¸‹è½½å®Œæˆäº†
	// XXX: ç¬¬ä¸€ä¸ªç‰ˆæœ¬å¹¶å‘åº¦ä¸é«˜ï¼Œæš‚æ—¶ä¸åŠ é”äº†ï¼Œé¸µé¸Ÿç®—æ³•å‡‘åˆä¸€ä¸‹
}

func NewBigFileReceiverWorker(header *BigFileHeader) *BigFileReceiverWorker {
	var blockSize uint64 = DefaultBlockSize
	return &BigFileReceiverWorker{
		header:    header,
		blockSize: blockSize,
	}
}

// init è¯»å–/æ–°å»º saveDir, è®¾ç½® numBlockã€savedBlock bitmap
func (w *BigFileReceiverWorker) init() {
	// åˆå§‹åŒ– numBlockã€savedBlock
	w.numBlock = w._numBlock()
	w.savedBlock = make([]bool, w.numBlock)

	// æ£€æŸ¥ saveDir, è¯»å– or æ–°å»º
	w.saveDir = w._saveDir()
	w.prepareSaveDir()

	// åŒæ­¥ savedBlock å’Œ saveDir é‡Œçš„çœŸå®æƒ…å†µ
	w.checkSaved()
}

// _numBlock è®¡ç®—æ­£ç¡®çš„å—æ•° NumBlockï¼Œè¿”å›ç»“æœã€‚
// æ³¨æ„ï¼Œè¿™ä¸ªæ–¹æ³•ä¸è®¾ç½® numBlock å­—æ®µ, è¦è®¾ç½®çš„è¯è¯·æ‰‹åŠ¨èµ‹å€¼:
//    w.numBlock = w.getNumBlock()
func (w *BigFileReceiverWorker) _numBlock() uint64 {
	n := w.header.FileSize() / w.blockSize
	r := w.header.FileSize() % w.blockSize
	if r > 0 {
		n += 1
	}
	return n
}

// _saveDir è®¡ç®—æ­£ç¡®çš„ä¸´æ—¶ä¿å­˜è·¯å¾„ saveDirï¼Œè¿”å›ç»“æœã€‚
// æ³¨æ„ï¼Œè¿™ä¸ªæ–¹æ³•ä¸è®¾ç½® saveDir å­—æ®µ, è¦è®¾ç½®çš„è¯è¯·æ‰‹åŠ¨èµ‹å€¼.
func (w *BigFileReceiverWorker) _saveDir() string {
	return fmt.Sprintf(".%s", FileIDString(w.header.FileID()))
}

// prepareSaveDir å‡†å¤‡ w.saveDir
// ä¹Ÿå°±æ˜¯æ£€æŸ¥ç›®å½•å­˜ä¸å­˜åœ¨å•¦ï¼Œä¸å­˜åœ¨å°±æ–°å»º
func (w *BigFileReceiverWorker) prepareSaveDir() {
	s, err := os.Stat(w.saveDir)
	if err != nil && os.IsNotExist(err) { // ä¸å­˜åœ¨
		if err = os.Mkdir(w.saveDir, 0755); err != nil { // æ–°å»º
			log.Fatal("BigFileReceiverWorker failed to make saveDir:", err)
		}
	} else if !s.IsDir() {
		log.Fatalf("BigFileReceiverWorker failed to use saveDir:"+
			" Please remove this file first: %s", w.saveDir)
	}
}

// checkSaved éå† w.saveDir é‡Œçš„æ–‡ä»¶ï¼Œæ‰¾å‡ºå·²ç»ä¸‹è½½äº†é‚£äº›æ–‡ä»¶ç‰‡æ®µï¼Œæ ‡è®°åˆ° w.savedBlock
func (w *BigFileReceiverWorker) checkSaved() {
	filepath.Walk(w.saveDir, func(path string, info os.FileInfo, err error) error {
		if info.IsDir() {
			return nil
		}
		if strings.HasSuffix(path, ".block") {
			var p int
			fmt.Sscanf(info.Name(), "%d", &p)
			if p < len(w.savedBlock) {
				w.savedBlock[p] = true
			} else {
				log.Printf("Unexpected saved block: %d (numBlock=%d)", p, w.numBlock)
			}
		}
		return nil
	})
}

// Run åˆå§‹åŒ– Workerï¼Œä» conn è¯·æ±‚ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ç‰‡æ®µã€‚
// å…¨éƒ¨ä¸‹è½½å®Œæˆåï¼Œåš mergeï¼Œæœ€åæŠŠ fileID å‘åˆ°è¯¥å‡½æ•°è¿”å›çš„ chanï¼Œå¹¶å›ä¼  header é€šçŸ¥å‘é€ç«¯ç»“æŸå·¥ä½œï¼Œã€‚
func (w *BigFileReceiverWorker) Run(conn net.Conn) chan string {
	if w.done != nil { // running
		return w.done
	}

	w.done = make(chan string)
	w.wait = make(chan int, 1) // Bugï¼šè¿™é‡Œä¸çŸ¥é“ä¸ºä»€ä¹ˆä¼šæ­»é”ï¼Œå¸¦ä¸Šç¼“å†²èƒ½è§£å†³ï¼›åŒæ—¶è¿˜æ”¶è·ä¸€ä¸ª featureï¼šç¼“å†²ç»™å¤šå¤§å°±åŒæ—¶è¯·æ±‚å‡ ä¸ª
	w.allSaved = make(chan bool)

	w.init()

	go w.requestAllMissing(conn, w.wait, w.allSaved)

	go func() { // ç­‰å¾…ä¸‹è½½å…¨éƒ¨å®Œæˆååš merge
		select {
		case <-w.allSaved:
			w.merge()
			correct := w.checkFinalSum()
			if correct {
				fmt.Println("[BigFile] receive successfully:", w.header.FileName())
			} else {
				fmt.Println("[BigFile] receive finished, but the file is BROKEN. "+
					"Please remove it and try again:", w.header.FileName())
			}

			go func() { // emmmm, è¯»å¤šä½™çš„æ•°æ®ï¼Œé˜²æ­¢å‘é€ç«¯ä¸€ç›´ç­‰å¾…æ— æ•ˆçš„å‘é€
				_ = conn.SetReadDeadline(time.Now().Add(time.Second))
				for {
					_, err := PacketFromReader(conn)
					if err != nil {
						break
					}
				}
				_ = conn.SetReadDeadline(time.Time{})
			}()

			//n, err := w.header.WriteTo(conn) // å›ä¼  header é€šçŸ¥å‘é€ç«¯ç»“æŸå·¥ä½œ
			//log.Println("[DEBUG] header -> sender:", n, err)
			_, _ = w.header.WriteTo(conn)

			w.done <- FileIDString(w.header.FileID())
		}
	}()

	return w.done
}

// requestAllMissing é€šè¿‡ conn è¯·æ±‚ä¸‹è½½æ‰€æœ‰ç¼ºå¤±ï¼ˆæœªä¸‹è½½ï¼‰çš„æ–‡ä»¶æ®µã€‚
// æ¯è¯·æ±‚ä¸€ä¸ªå°±æŠŠ blockIndex æ”¾åˆ° wait ä¿¡é“é‡Œï¼Œç­‰å¾…æœ‰äºº (w.Receive å•¦) æŠŠå€¼å–èµ°ï¼›
// å¦‚æœ wait ä¸º nil åˆ™ä¸ç­‰å¾…ã€‚
func (w *BigFileReceiverWorker) requestAllMissing(conn net.Conn, wait chan int, allSaved chan bool) {
	var err error
	for m := w.missingBlockIndices(); len(m) > 0; m = w.missingBlockIndices() {
		for _, i := range m {
			if !w.savedBlock[i] {
				err = w.requestDownload(i, conn)
			}
			if (err == nil) && (wait != nil) {
			WAIT:
				for {
					select {
					case wait <- i:
						break WAIT
					case <-time.After(1 * time.Millisecond):
						//conn.SetReadDeadline(time.Now().Add(1 * time.Millisecond))
						p, err := PacketFromReader(conn)
						//conn.SetReadDeadline(time.Time{})
						if err == nil {
							DistributerInstance().Receive(p, conn)
						}
					}
				}
			}
		}
		w.checkSaved()
	}
	allSaved <- true
}

// missingBlockIndices è¿”å›æ‰€æœ‰æ²¡ä¸‹è½½çš„å—ç´¢å¼•
func (w *BigFileReceiverWorker) missingBlockIndices() []int {
	missing := make([]int, 0)
	for i := 0; i < len(w.savedBlock); i++ {
		if !w.savedBlock[i] {
			missing = append(missing, i)
		}
	}
	return missing
}

// requestDownload å‘ conn å‘é€ä¸‹è½½ä¸€ä¸ªæ–‡ä»¶ç‰‡æ®µçš„è¯·æ±‚
func (w *BigFileReceiverWorker) requestDownload(blockIndex int, conn net.Conn) error {
	//log.Println("[DEBUG] BigFileReceiverWorker requestDownload:", blockIndex)

	start := w.blockSize * uint64(blockIndex) // offset of file

	req := NewBigFileRequest(w.header.FileID(), start, w.blockSize)

	if _, err := req.WriteTo(conn); err != nil {
		//log.Println("BigFileRequest send failed:", err)
		return err
	}
	return nil
}

// Receive æ¥æ”¶ä¸€ä¸ªè¯¥ Worker è´Ÿè´£çš„æ–‡ä»¶çš„ BigFileResponse
func (w *BigFileReceiverWorker) Receive(response *BigFileResponse) {
	//log.Println("[DEBUG] BigFileReceiverWorker.Receive", FileIDString(response.FileID()), response.Start())
	if FileIDString(response.FileID()) != FileIDString(w.header.FileID()) {
		// ä¸æ˜¯è¿™ä¸ª worker è´Ÿè´£çš„å•Šï¼Œåˆ†å‘é”™äº†ï¼Œmaster ä¸å¯¹åŠ²ğŸ¤¨
		log.Fatalf("BigFileReceiverWorker (for %x) got an unexpected Response (for %x)",
			w.header.FileID(), response.FileID())
		return
	}

	block := response.Start() / w.blockSize

	err := w.saveBlock(block, response.FileContent())
	if err == nil { // æ— é”™: ä¿å­˜æˆåŠŸ
		w.savedBlock[block] = true
	}

	// å”¤é†’ requestAllMissing, ç»§ç»­è¯·æ±‚
	if w.wait != nil {
		select {
		case <-w.wait:
			return
		case <-time.After(10 * time.Second): // timeout, è¿™ä¸ªåº”è¯¥æ˜¯ä¸ªé”™è¯¯
			log.Println("BigFileReceiverWorker Error: Receive <-w.wait timeout")
		}
	}
}

// saveBlock ä¿å­˜ä¸€ä¸ªæ–‡ä»¶å—
func (w *BigFileReceiverWorker) saveBlock(block uint64, fileContent []byte) error {
	name := w.BlockTmpFilePath(block)

	file, err := os.OpenFile(name, os.O_WRONLY|os.O_TRUNC|os.O_CREATE, 0666)
	if err != nil {
		log.Printf("[BigFileReceiverWorker] block %v save failed: %v\n", block, err)
		return err
	}
	defer file.Close()

	if n, err := file.Write(fileContent); err != nil {
		log.Printf("[BigFileReceiverWorker] block %v save failed: %v\n", block, err)
		return err
	} else {
		log.Printf("[BigFileReceiverWorker] block %v/%v: %d Bytes saved.\n", block, w.numBlock-1, n)
	}
	return nil
}

// merge åˆå¹¶æ–‡ä»¶:
// æŠŠæ‰€æœ‰å—æ–‡ä»¶é€ä¸ªè¿½åŠ å…¥ 0.block, ç„¶ååˆ é™¤, å®Œæˆååªä¼šå‰©ä¸‹ 0.block ä¸€ä¸ªæ–‡ä»¶,
// æœ€å mv saveDir/0.block $PWD/{FileName}
func (w *BigFileReceiverWorker) merge() {
	filePath0 := w.BlockTmpFilePath(0)

	mergedFile, err := os.OpenFile(filePath0, os.O_APPEND|os.O_WRONLY, os.ModeAppend)
	if err != nil {
		log.Fatalf("BigFileReceiverWorker merge fileID=%x failed: failed to open 0.block: %v",
			w.header.FileID(), err)
	}

	for i := uint64(1); i < w.numBlock; i++ {
		filePath := w.BlockTmpFilePath(i)
		file, err := os.Open(filePath)
		if err != nil {
			_ = mergedFile.Close()
			log.Fatalf("BigFileReceiverWorker merge fileID=%x failed: failed to open %d.block: %v",
				w.header.FileID(), i, err)
		}
		_, err = io.Copy(mergedFile, file)
		if err != nil {
			_ = file.Close()
			_ = mergedFile.Close()
			log.Fatalf("BigFileReceiverWorker merge fileID=%x failed: failed to merge %d.block: %v",
				w.header.FileID(), i, err)
		}

		_ = file.Close()
		_ = os.Remove(filePath)
	}

	log.Printf("[BigFileReceiverWorker] big file merge: %s => %s",
		FileIDString(w.header.FileID()), w.header.FileName())

	_ = mergedFile.Close()

	err = os.Rename(filePath0, w.header.FileName())
	if err != nil {
		log.Fatalln(err)
	}
	os.RemoveAll(w.saveDir)
}

// checkFinalSum æ£€æŸ¥æœ€ç»ˆ merge å¾—åˆ°çš„æ–‡ä»¶ ($PWD/{FileName}) çš„ md5
// åŒ¹é…åˆ™è¿”å› trueï¼Œå¦åˆ™ false
func (w *BigFileReceiverWorker) checkFinalSum() (ok bool) {
	f, err := os.Open(w.header.FileName())
	if err != nil {
		log.Fatalln("BigFileReceiverWorker checkFinalSum:", err)
	}
	defer f.Close()

	h := md5.New()
	if _, err := io.Copy(h, f); err != nil {
		log.Fatal(err)
	}
	sum := h.Sum(nil)

	return string(sum) == string(w.header.FileHash())
}

// BlockTmpFilePath è·å–ä¸€ä¸ªæ–‡ä»¶çš„ä¸€ä¸ªå—çš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„ã€‚
// returns "{fileIDString}/{block}.block"
func (w BigFileReceiverWorker) BlockTmpFilePath(block uint64) string {
	return path.Join(
		w.saveDir,
		fmt.Sprintf("%d.block", block),
	)
}

// æ³¨å†Œ BigFileReceiver
func init() {
	bigFileReceiver := NewBigFileReceiver()
	DistributerInstance().Register(PacketTypeBigFileHeader, bigFileReceiver)
	DistributerInstance().Register(PacketTypeBigFileResponse, bigFileReceiver)
}
